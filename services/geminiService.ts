
import { GoogleGenAI, Modality, Part, GenerateContentResponse, HarmCategory, HarmBlockThreshold, Type } from "@google/genai";
import { ImageFile, AudioFile } from '../types';

if (!process.env.API_KEY) {
  throw new Error("API_KEY environment variable not set");
}

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

const safetySettings = [
  {
    category: HarmCategory.HARM_CATEGORY_HARASSMENT,
    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
  },
];

const handleApiResponse = (response: GenerateContentResponse): ImageFile => {
    for (const part of response.candidates?.[0]?.content?.parts || []) {
        if (part.inlineData) {
            return {
                base64: part.inlineData.data,
                mimeType: part.inlineData.mimeType,
                name: 'generated-image.png',
            };
        }
    }
    
    const safetyText = response.candidates?.[0]?.finishReason;
    if (safetyText && safetyText !== 'STOP') {
        throw new Error(`Image generation failed due to safety settings: ${safetyText}`);
    }

    throw new Error('No image was generated by the model.');
};

export async function generateImage(
  productImages: ImageFile[],
  prompt: string,
  styleImages: ImageFile[] | null,
  aspectRatio: string = "1:1"
): Promise<ImageFile> {
  const model = 'gemini-2.5-flash-image';
  const parts: Part[] = [];

  // Add product references if they exist
  if (productImages && productImages.length > 0) {
    productImages.forEach(productImage => {
        parts.push({
          inlineData: {
            data: productImage.base64,
            mimeType: productImage.mimeType,
          },
        });
      });
  }
  
  parts.push({ text: prompt });

  if (styleImages && styleImages.length > 0) {
    styleImages.forEach(styleImage => {
      parts.push({
        inlineData: {
          data: styleImage.base64,
          mimeType: styleImage.mimeType,
        },
      });
    });
  }

  try {
    const response = await ai.models.generateContent({
      model: model,
      contents: { parts: parts },
      config: {
        imageConfig: { aspectRatio: aspectRatio as any }
      },
      safetySettings: safetySettings,
    });

    return handleApiResponse(response);

  } catch (error) {
    console.error('Error calling Gemini API for generation:', error);
    throw error;
  }
}

export async function editImage(
  baseImage: ImageFile,
  prompt: string,
): Promise<ImageFile> {
  const model = 'gemini-2.5-flash-image';

  const parts: Part[] = [
    {
      inlineData: {
        data: baseImage.base64,
        mimeType: baseImage.mimeType,
      },
    },
    { text: prompt },
  ];

  try {
    const response = await ai.models.generateContent({
      model: model,
      contents: { parts: parts },
      safetySettings: safetySettings,
    });

    return handleApiResponse(response);

  } catch (error) {
    console.error('Error calling Gemini API for editing:', error);
    throw error;
  }
}

export async function expandImage(
  image: ImageFile,
  prompt: string
): Promise<ImageFile> {
  return editImage(image, prompt);
}

export async function analyzeImageForPrompt(
  images: ImageFile[],
  instructions: string
): Promise<string> {
  const model = 'gemini-3-flash-preview';
  const parts: Part[] = [];

  images.forEach(image => {
    parts.push({
      inlineData: {
        data: image.base64,
        mimeType: image.mimeType,
      },
    });
  });

  let textPrompt = `Analyze the provided image(s) in detail. Craft a descriptive prompt for an AI model. Instruction: ${instructions}`;
  parts.push({ text: textPrompt });

  try {
    const response: GenerateContentResponse = await ai.models.generateContent({
      model: model,
      contents: { parts: parts },
      safetySettings: safetySettings,
    });
    return response.text?.trim() || '';
  } catch (error) {
    throw error;
  }
}

export async function analyzeStyleImage(images: ImageFile[]): Promise<string> {
  const model = 'gemini-3-flash-preview';
  const parts: Part[] = images.map(img => ({
    inlineData: {
      data: img.base64,
      mimeType: img.mimeType,
    },
  }));
  parts.push({ text: "Analyze the visual style of these images. Describe the lighting, color palette, mood, and aesthetic in detail for a text-to-image prompt." });

  try {
    const response = await ai.models.generateContent({
      model,
      contents: { parts },
    });
    return response.text?.trim() || '';
  } catch (error) {
    console.error('Error analyzing style image:', error);
    throw error;
  }
}

export async function analyzeLogoForBranding(images: ImageFile[]): Promise<{ colors: string[] }> {
  const model = 'gemini-3-flash-preview';
  const parts: Part[] = images.map(img => ({
    inlineData: {
      data: img.base64,
      mimeType: img.mimeType,
    },
  }));
  parts.push({ text: "Analyze this logo and extract the primary brand colors. Return them as a JSON object with a 'colors' key containing a string array of hex codes." });

  try {
    const response = await ai.models.generateContent({
      model,
      contents: { parts },
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            colors: {
              type: Type.ARRAY,
              items: { type: Type.STRING },
              description: "Hex color codes representing the logo palette"
            }
          },
          required: ["colors"]
        }
      }
    });
    const text = response.text || '{"colors": []}';
    return JSON.parse(text);
  } catch (error) {
    console.error('Error analyzing logo for branding:', error);
    throw error;
  }
}

export async function generatePromptFromText(instructions: string): Promise<string> {
  const model = 'gemini-3-flash-preview';
  const prompt = `Expand this idea into a detailed text-to-image prompt: "${instructions}"`;
  try {
    const response: GenerateContentResponse = await ai.models.generateContent({
      model: model,
      contents: prompt,
      safetySettings: safetySettings,
    });
    return response.text?.trim() || '';
  } catch (error) {
    throw error;
  }
}

export async function translateText(text: string): Promise<string> {
  const model = 'gemini-3-flash-preview';
  const prompt = `Translate the following text to English, preserving any technical or descriptive nuances: "${text}"`;
  try {
    const response: GenerateContentResponse = await ai.models.generateContent({
      model: model,
      contents: prompt,
    });
    return response.text?.trim() || '';
  } catch (error) {
    throw error;
  }
}

export async function generateSpeech(text: string, styleInstructions: string, voiceName: string): Promise<AudioFile> {
  const model = "gemini-2.5-flash-preview-tts";
  const prompt = `Speak the following text ${styleInstructions ? '(' + styleInstructions + ')' : ''}: ${text}`;
  
  try {
    const response = await ai.models.generateContent({
      model,
      contents: [{ parts: [{ text: prompt }] }],
      config: {
        responseModalities: [Modality.AUDIO],
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: { voiceName },
          },
        },
      },
    });

    const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    if (!base64Audio) {
      throw new Error('No audio data returned from the model.');
    }

    return {
      base64: base64Audio,
      name: `voiceover-${Date.now()}.wav`,
    };
  } catch (error) {
    console.error('Error generating speech:', error);
    throw error;
  }
}

export async function generateCampaignPlan(
    productImages: ImageFile[],
    userPrompt: string,
    targetMarket: string = "Global",
    dialect: string = "English"
): Promise<any[]> {
    const model = 'gemini-3-flash-preview';
    const parts: Part[] = [];

    if (productImages && productImages.length > 0) {
        productImages.forEach(img => parts.push({ inlineData: { data: img.base64, mimeType: img.mimeType } }));
    }

    const instruction = `Act as a professional Creative Director and Marketing Strategist. 
    Target Market: ${targetMarket}. Requested Content Dialect/Language: ${dialect}.
    Goal: "${userPrompt}". 
    
    Task: Generate 9 unique campaign post ideas tailored for the specified market and written in the requested dialect.
    Return a JSON array where each object has:
    - id: string
    - scenario: highly descriptive visual prompt for AI image generation (English). If no product image was provided, describe the subject/product from the user's goal.
    - caption: engaging social media caption written STRICTLY in the specified dialect (${dialect})
    - tov: a short, catchy text suggestion or hook (max 5-7 words) derived from the caption, intended to be written directly on the design/visual itself.
    - schedule: recommended posting day/time for the ${targetMarket} market.
    Return ONLY the raw JSON array.`;

    parts.push({ text: instruction });

    try {
        const response = await ai.models.generateContent({
            model,
            contents: { parts },
            config: {
                responseMimeType: "application/json",
                responseSchema: {
                    type: Type.ARRAY,
                    items: {
                        type: Type.OBJECT,
                        properties: {
                            id: { type: Type.STRING },
                            scenario: { type: Type.STRING },
                            caption: { type: Type.STRING },
                            tov: { type: Type.STRING },
                            schedule: { type: Type.STRING },
                        },
                        required: ["id", "scenario", "caption", "tov", "schedule"]
                    }
                }
            }
        });
        const text = response.text || '[]';
        return JSON.parse(text.trim());
    } catch (err) {
        console.error("Plan generation failed:", err);
        throw err;
    }
}

export async function analyzeProductForCampaign(productImages: ImageFile[]): Promise<string> {
    const model = 'gemini-3-flash-preview';
    const parts: Part[] = [];
    productImages.forEach(img => parts.push({ inlineData: { data: img.base64, mimeType: img.mimeType } }));

    const prompt = `Analyze these image(s) to identify the product/service category and its market positioning. 
    Return a concise analysis including:
    1. Identified Category (e.g. Luxury Watches, Organic Skincare, Tech Services).
    2. Best Market Fit: Describe the ideal setting and audience for this product based on current market trends.
    Format as a clear, professional summary.`;
    
    parts.push({ text: prompt });

    try {
        const response: GenerateContentResponse = await ai.models.generateContent({
            model,
            contents: { parts },
        });
        return response.text?.trim() || '';
    } catch (error) {
        throw error;
    }
}
